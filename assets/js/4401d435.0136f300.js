"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[47842],{35318:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>k});var a=n(27378);function i(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){i(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,i=function(e,t){if(null==e)return{};var n,a,i={},r=Object.keys(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||(i[n]=e[n]);return i}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(a=0;a<r.length;a++)n=r[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(i[n]=e[n])}return i}var l=a.createContext({}),c=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},p=function(e){var t=c(e.components);return a.createElement(l.Provider,{value:t},e.children)},u={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,i=e.mdxType,r=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),m=c(n),k=i,h=m["".concat(l,".").concat(k)]||m[k]||u[k]||r;return n?a.createElement(h,o(o({ref:t},p),{},{components:n})):a.createElement(h,o({ref:t},p))}));function k(e,t){var n=arguments,i=t&&t.mdxType;if("string"==typeof e||i){var r=n.length,o=new Array(r);o[0]=m;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s.mdxType="string"==typeof e?e:i,o[1]=s;for(var c=2;c<r;c++)o[c]=n[c];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},47522:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>o,default:()=>u,frontMatter:()=>r,metadata:()=>s,toc:()=>c});var a=n(25773),i=(n(27378),n(35318));const r={title:"Access the Kafka Cluster by APISIX Gateway",authors:[{name:"Meng Yan",title:"Author",url:"https://github.com/yanmxa"}],keywords:["Message Queue","Kafka","Gateway","Strimzi"],description:"A few days ago, I added Apache APISIX as a proxy to an Apache Kafka cluster to manage authentication and authorization. Now, I created a custom authorization plugin in Go for the Kafka cluster.",tags:["Ecosystem"],image:"https://static.apiseven.com/uploads/2023/12/29/oJyQz1c4_A&K_Cover.png"},o=void 0,s={permalink:"/blog/2023/12/26/access-kafka-by-apisix",source:"@site/blog/2023/12/26/access-kafka-by-apisix.md",title:"Access the Kafka Cluster by APISIX Gateway",description:"A few days ago, I added Apache APISIX as a proxy to an Apache Kafka cluster to manage authentication and authorization. Now, I created a custom authorization plugin in Go for the Kafka cluster.",date:"2023-12-26T00:00:00.000Z",formattedDate:"December 26, 2023",tags:[{label:"Ecosystem",permalink:"/blog/tags/ecosystem"}],readingTime:4.46,truncated:!0,authors:[{name:"Meng Yan",title:"Author",url:"https://github.com/yanmxa"}],prevItem:{title:"Biweekly Report (December 18 - December 31)",permalink:"/blog/2024/01/03/bi-weekly-report"},nextItem:{title:"Building a Robust 'Highway' with APISIX: Gateway and Protocol Performance Optimization",permalink:"/blog/2023/12/26/zhengcaiyun-uses-apisix"}},l={authorsImageUrls:[void 0]},c=[{value:"Prerequisites",id:"prerequisites",children:[],level:2},{value:"Expose the Kafka Cluster by KafkaBridge",id:"expose-the-kafka-cluster-by-kafkabridge",children:[],level:2},{value:"Running APISIX on Openshift",id:"running-apisix-on-openshift",children:[],level:2},{value:"Develop an Authentication Plugin with Golang",id:"develop-an-authentication-plugin-with-golang",children:[],level:2},{value:"References",id:"references",children:[],level:2}],p={toc:c};function u(e){let{components:t,...n}=e;return(0,i.kt)("wrapper",(0,a.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,i.kt)("blockquote",null,(0,i.kt)("p",{parentName:"blockquote"},"This blog shows how to use Apache APISIX to develop a customize authorization plugin for the kafka cluster.")),(0,i.kt)("h2",{id:"prerequisites"},"Prerequisites"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Have a running OpenShift cluster"),(0,i.kt)("li",{parentName:"ul"},"Run a Kafka cluster with ",(0,i.kt)("a",{parentName:"li",href:"https://github.com/strimzi/strimzi-kafka-operator"},"strimzi kafka operator")),(0,i.kt)("li",{parentName:"ul"},"Install ",(0,i.kt)("a",{parentName:"li",href:"https://kubernetes.io/docs/reference/kubectl"},"kubectl"),", ",(0,i.kt)("a",{parentName:"li",href:"https://docs.openshift.com/container-platform/4.11/cli_reference/openshift_cli/getting-started-cli.html"},"OpenShift CLI")," and curl on host")),(0,i.kt)("h2",{id:"expose-the-kafka-cluster-by-kafkabridge"},"Expose the Kafka Cluster by KafkaBridge"),(0,i.kt)("p",null,"To simplify the configuration setting for the kafka. I provision the kafka by ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/strimzi/strimzi-kafka-operator"},"strimzi-kafka-operator"),". In order to make Kafka expose interfaces externally like other services, I use ",(0,i.kt)("inlineCode",{parentName:"p"},"KafkaBridge")," to transform it into an HTTP service."),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Create the ",(0,i.kt)("inlineCode",{parentName:"li"},"KafkaBridge"))),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"# namespace\nKAFKA_NAMESPACE=kafka\n\n# create kafka bridge instance\ncat <<EOF | oc apply -f -\napiVersion: kafka.strimzi.io/v1beta2\nkind: KafkaBridge\nmetadata:\n  name: strimzi-kafka-bridge\n  namespace: ${KAFKA_NAMESPACE}\nspec:\n  bootstrapServers: kafka-kafka-bootstrap.${KAFKA_NAMESPACE}.svc:9092\n  http:\n    port: 8080\n  replicas: 1\nEOF\n")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Verification")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'KAFKA_NAMESPACE=kafka\n# forward 8080 by bridge pod\nkubectl -n ${KAFKA_NAMESPACE} port-forward $(kubectl get pods -l strimzi.io/cluster=strimzi-kafka-bridge -n ${KAFKA_NAMESPACE} -o jsonpath="{.items[0].metadata.name}") 8080:8080\n\n# or forward 8080 by svc\nkubectl -n ${KAFKA_NAMESPACE} port-forward svc/$(kubectl get svc -l strimzi.io/cluster=strimzi-kafka-bridge -n ${KAFKA_NAMESPACE} -o jsonpath="{.items[0].metadata.name}") 8080:8080\n\n# list topic\ncurl http://localhost:8080/topics\n\n# consume message with the consumer\nwhile true; do curl -X GET http://localhost:8080/consumers/strimzi-kafka-consumer-group/instances/strimzi-kafka-consumer/records \\\n-H \'accept: application/vnd.kafka.json.v2+json\'; sleep 1; done\n')),(0,i.kt)("h2",{id:"running-apisix-on-openshift"},"Running APISIX on Openshift"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Install APISIX on ROSA")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"oc create sa apisix-sa -n apisix\noc adm policy add-scc-to-user anyuid -z apisix-sa -n apisix\n\nhelm install apisix apisix/apisix \\\n  --set gateway.type=NodePort \\\n  --set etcd.podSecurityContext.enabled=false \\\n  --set etcd.containerSecurityContext.enabled=false \\\n  --set serviceAccount.name=apisix-sa \\\n  --namespace apisix\n")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Configure the Kafka Route with Admin API")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'# forward 9180 port to local host\nkubectl -n apisix port-forward $(kubectl get pods -l app.kubernetes.io/name=apisix -n apisix -o jsonpath="{.items[0].metadata.name}") 9180:9180\n\n# the bridge service name can be accessed by\n# kubectl get svc -l strimzi.io/cluster=strimzi-kafka-bridge -n $KAFKA_NAMESPACE -o jsonpath="{.items[0].metadata.name}"\ncurl "http://127.0.0.1:9180/apisix/admin/routes/1" \\\n-H "X-API-KEY: edd1c9f034335f136f87ad84b625c8f1" -X PUT -d \'\n{\n  "methods": ["GET", "POST", "DELETE", "PUT"],\n  "host": "example.com",\n  "uri": "/*",\n  "plugins": {\n    "ext-plugin-post-resp": {\n      "conf": [\n        {"name":"my-response-rewrite", "value":"{\\"tag\\":\\"\\"}"}\n      ]\n    }\n  },\n  "upstream": {\n    "type": "roundrobin",\n    "nodes": {\n      "strimzi-kafka-bridge-bridge-service.kafka.svc:8080": 1\n    }\n  }\n}\'\n')),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Request the Kafka Service with Client API")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'# forward the http api of apisix to local host\nkubectl -n apisix port-forward $(kubectl get pods -l app.kubernetes.io/name=apisix -n apisix -o jsonpath="{.items[0].metadata.name}") 9080:9080\n\n# list topic\ncurl --verbose --header "Host: example.com" http://localhost:9080/topics\n\n# send message to the topic\ncurl --header "Host: example.com" --location \'http://localhost:9080/topics/event\' -H \'Content-Type: application/vnd.kafka.json.v2+json\' --data \\\n\'{\n   "records":[\n      {\n         "key":"event5",\n         "value": "hello5"\n      },\n      {\n         "key":"event6",\n         "value": "world6"\n      }\n   ]\n}\'\n\n# create a kafka consumer in a new consumer group\ncurl --header "Host: example.com" -X POST http://localhost:9080/consumers/strimzi-kafka-consumer-group \\\n  -H \'content-type: application/vnd.kafka.v2+json\' \\\n  -d \'{\n    "name": "strimzi-kafka-consumer",\n    "auto.offset.reset": "earliest",\n    "format": "json",\n    "enable.auto.commit": true,\n    "fetch.min.bytes": 512,\n    "consumer.request.timeout.ms": 30000\n  }\'\n\n# subscribe to the topic\ncurl --header "Host: example.com" -X POST http://localhost:9080/consumers/strimzi-kafka-consumer-group/instances/strimzi-kafka-consumer/subscription \\\n  -H \'content-type: application/vnd.kafka.v2+json\' \\\n  -d \'{\n    "topics": [\n        "event"\n    ]\n}\'\n\n# consume message with the consumer\nwhile true; do curl --header "Host: example.com" -X GET http://localhost:9080/consumers/strimzi-kafka-consumer-group/instances/strimzi-kafka-consumer/records \\\n-H \'accept: application/vnd.kafka.json.v2+json\'; sleep 1; done\n')),(0,i.kt)("h2",{id:"develop-an-authentication-plugin-with-golang"},"Develop an Authentication Plugin with Golang"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Develop a validation plugin for the certificates"),(0,i.kt)("p",{parentName:"li"},"I develop the plugin leverage the ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/apache/apisix-go-plugin-runner"},"Go plugin runner"),". The plugin is just read the certificate from the header and then validate it. You can visit ",(0,i.kt)("a",{parentName:"p",href:"https://github.com/yanmxa/apisix-go-plugin-runner/commit/84adcb2447287d48419c312f8aba8039c4b1f32d"},"this")," for more detail.")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Build the APISIX Image with the above Plugin"))),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"git clone git@github.com:apache/apisix-go-plugin-runner.git\n# develop the plugin\n...\n# build binary\nmake build\n# create Dockerfile to add the build binary\n`Dockerfile\nFROM apache/apisix:3.6.0-debian\nCOPY ./go-runner /usr/local/apisix/apisix-go-plugin-runner/go-runner\n`\n# build and push image\ndocker build -f ./Dockerfile -t quay.io/myan/apisix-360-go:0.1 .\ndocker push quay.io/myan/apisix-360-go:0.1\n")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("p",{parentName:"li"},"Startup the Plugin When Running the Server"),(0,i.kt)("p",{parentName:"li"},"Modify the ",(0,i.kt)("inlineCode",{parentName:"p"},"config.yaml")," by ",(0,i.kt)("inlineCode",{parentName:"p"},"apisix")," ConfigMap."))),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},'  etcd:\n    host:                # it\'s possible to define multiple etcd hosts addresses of the same etcd cluster.\n      - "http://apisix-etcd.apisix.svc.cluster.local:2379"\n    prefix: "/apisix"    # configuration prefix in etcd\n    timeout: 30          # 30 seconds\n...\n# Nginx will hide all environment variables by default. So you need to declare your variable first in the conf/config.yaml\n# https://github.com/apache/apisix/blob/master/docs/en/latest/external-plugin.md\nnginx_config:\n  envs:\n    - APISIX_LISTEN_ADDRESS\n    - APISIX_CONF_EXPIRE_TIME\n\next-plugin:\n  # path_for_test: "/tmp/runner.sock"\n  cmd: ["/usr/local/apisix/apisix-go-plugin-runner/go-runner", "run", "-m", "prod"]\n')),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Replace the APISIX Deployment Image")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"# image: quay.io/myan/apisix-360-go:0.1\nkubectl set image deployment/apisix apisix=quay.io/myan/apisix-360-go:0.1\n")),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},"Verification")),(0,i.kt)("pre",null,(0,i.kt)("code",{parentName:"pre",className:"language-bash"},"# set the certificate\nCERT_CONTENT_BASE64=$(base64 < rest/client.crt)\n\n# list the topics\ncurl -i 'http://127.0.0.1:9080/topics' \\\n-H 'Host: example.com' \\\n-H 'Content-Type: application/vnd.kafka.json.v2+json' \\\n-H 'Source: client' \\\n-H \"Client-Certificate: $CERT_CONTENT_BASE64\"\n\n# create consumer\ncurl -X POST 'http://localhost:9080/consumers/strimzi-kafka-consumer-group' \\\n  -H 'Host: example.com' \\\n  -H 'Content-Type: application/vnd.kafka.json.v2+json' \\\n  -H 'Source: client' \\\n  -H \"Client-Certificate: $CERT_CONTENT_BASE64\" \\\n  -d '{\n   \"name\": \"strimzi-kafka-consumer\",\n   \"auto.offset.reset\": \"earliest\",\n   \"format\": \"json\",\n   \"enable.auto.commit\": true,\n   \"fetch.min.bytes\": 512,\n   \"consumer.request.timeout.ms\": 30000\n}'\n\n# subscribe topic event with the consumer group 'strimzi-kafka-consumer'\ncurl -X POST 'http://localhost:9080/consumers/strimzi-kafka-consumer-group/instances/strimzi-kafka-consumer/subscription' \\\n  -H 'Host: example.com' \\\n  -H 'Content-Type: application/vnd.kafka.json.v2+json' \\\n  -H 'Source: client' \\\n  -H \"Client-Certificate: $CERT_CONTENT_BASE64\" \\\n  -d '{\n   \"topics\": [\"event\"]\n}'\n\n# consume message\ncurl -X GET 'http://localhost:9080/consumers/strimzi-kafka-consumer-group/instances/strimzi-kafka-consumer/records' \\\n  -H 'Host: example.com' \\\n  -H 'Accept: application/vnd.kafka.json.v2+json' \\\n  -H 'Source: client' \\\n  -H \"Client-Certificate: $CERT_CONTENT_BASE64\" \\\n")),(0,i.kt)("h2",{id:"references"},"References"),(0,i.kt)("ul",null,(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://apisix.apache.org/zh/docs/ingress-controller/tutorials/how-to-use-go-plugin-runner-in-apisix-ingress/"},"How to use go-plugin-runner with APISIX Ingress")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://apisix.apache.org/blog/2021/08/19/go-makes-apache-apisix-better/"},"How to use Go to develop Apache APISIX plugin")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://zhuanlan.zhihu.com/p/613540331"},"APISIX\u4e4bGo\u63d2\u4ef6\u5f00\u53d1")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://www.fdevops.com/2022/10/09/casbin-apisix-31182"},"\u7ed3\u5408 casbin \u4e3a APISIX \u5f00\u53d1\u4e00\u4e2a\u63a5\u53e3\u6743\u9650\u6821\u9a8c\u63d2\u4ef6")),(0,i.kt)("li",{parentName:"ul"},(0,i.kt)("a",{parentName:"li",href:"https://blog.csdn.net/weixin_42873928/article/details/123279381"},"Docker\u90e8\u7f72 apisix \u5e76\u4f7f\u7528golang\u63d2\u4ef6(\u81ea\u5b9a\u4e49\u9274\u6743\u65b9\u5f0f)"))))}u.isMDXComponent=!0}}]);