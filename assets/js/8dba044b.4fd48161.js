"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[59990],{35318:(e,t,n)=>{n.d(t,{Zo:()=>u,kt:()=>d});var a=n(27378);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function i(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function o(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?i(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):i(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function l(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},i=Object.keys(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);for(a=0;a<i.length;a++)n=i[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var s=a.createContext({}),p=function(e){var t=a.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):o(o({},t),e)),n},u=function(e){var t=p(e.components);return a.createElement(s.Provider,{value:t},e.children)},c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},m=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,i=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),m=p(n),d=r,h=m["".concat(s,".").concat(d)]||m[d]||c[d]||i;return n?a.createElement(h,o(o({ref:t},u),{},{components:n})):a.createElement(h,o({ref:t},u))}));function d(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var i=n.length,o=new Array(i);o[0]=m;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:r,o[1]=l;for(var p=2;p<i;p++)o[p]=n[p];return a.createElement.apply(null,o)}return a.createElement.apply(null,n)}m.displayName="MDXCreateElement"},51870:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>s,contentTitle:()=>o,default:()=>c,frontMatter:()=>i,metadata:()=>l,toc:()=>p});var a=n(25773),r=(n(27378),n(35318));const i={title:"Announcing APISIX Integration with AI/ML API",authors:[{name:"Yilia Lin",title:"Technical Writer",url:"https://github.com/Yilialinn",image_url:"https://github.com/Yilialinn.png"}],keywords:["API gateway","Apache APISIX","AI","AI/ML API","AI plugins"],description:"Apache APISIX supports 300+ LLMs through the integration with AI/ML API. Get your secure, single-endpoint access to AI models like GPT-4 and Claude, and more.",tags:["Ecosystem"],image:"https://static.api7.ai/uploads/2025/07/23/d1O3mllW_apisix-ai-ml-api.webp"},o=void 0,l={permalink:"/blog/2025/07/29/announcing-integration-of-apisix-and-ai-ml-api",source:"@site/blog/2025/07/29/announcing-integration-of-apisix-and-ai-ml-api.md",title:"Announcing APISIX Integration with AI/ML API",description:"Apache APISIX supports 300+ LLMs through the integration with AI/ML API. Get your secure, single-endpoint access to AI models like GPT-4 and Claude, and more.",date:"2025-07-29T00:00:00.000Z",formattedDate:"July 29, 2025",tags:[{label:"Ecosystem",permalink:"/blog/tags/ecosystem"}],readingTime:3.405,truncated:!0,authors:[{name:"Yilia Lin",title:"Technical Writer",url:"https://github.com/Yilialinn",image_url:"https://github.com/Yilialinn.png",imageURL:"https://github.com/Yilialinn.png"}],prevItem:{title:"Load Balancing AI/ML API with Apache APISIX",permalink:"/blog/2025/07/31/load-balancing-between-ai-ml-api-with-apisix"},nextItem:{title:"2025 Monthly Report (June 01 - June 30)",permalink:"/blog/2025/06/30/2025-june-monthly-report"}},s={authorsImageUrls:[void 0]},p=[{value:"Introduction",id:"introduction",children:[],level:2},{value:"Proxy to OpenAI via AI/ML API",id:"proxy-to-openai-via-aiml-api",children:[{value:"Prerequisites",id:"prerequisites",children:[],level:3},{value:"Configure the Route",id:"configure-the-route",children:[],level:3},{value:"Test the Integration",id:"test-the-integration",children:[],level:3},{value:"Verify Response",id:"verify-response",children:[],level:3}],level:2},{value:"Core Use Cases",id:"core-use-cases",children:[],level:2},{value:"Conclusion",id:"conclusion",children:[{value:"More Resources",id:"more-resources",children:[],level:3}],level:2}],u={toc:p};function c(e){let{components:t,...n}=e;return(0,r.kt)("wrapper",(0,a.Z)({},u,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("blockquote",null,(0,r.kt)("p",{parentName:"blockquote"},"We're thrilled to announce that ",(0,r.kt)("strong",{parentName:"p"},"AI/ML API")," has become a supported provider to the ",(0,r.kt)("inlineCode",{parentName:"p"},"ai-proxy"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"ai-proxy-multi"),", and ",(0,r.kt)("inlineCode",{parentName:"p"},"ai-request-rewrite")," plugins in ",(0,r.kt)("strong",{parentName:"p"},"Apache APISIX"),". All the AI/ML APIs will be supported in the next APISIX version.")),(0,r.kt)("h2",{id:"introduction"},"Introduction"),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://aimlapi.com/"},"AI/ML API")," is a single endpoint that gives you access to more than 300 ready-to-use AI models\u2014large language models, embeddings, image and audio tools\u2014through one standard REST interface. It is used by over 150,000 developers and organizations as a centralized LLM API gateway."),(0,r.kt)("p",null,"We're thrilled to announce that ",(0,r.kt)("strong",{parentName:"p"},"AI/ML API")," has become a supported provider to the ",(0,r.kt)("inlineCode",{parentName:"p"},"ai-proxy"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"ai-proxy-multi"),", and ",(0,r.kt)("inlineCode",{parentName:"p"},"ai-request-rewrite")," plugins in ",(0,r.kt)("strong",{parentName:"p"},"Apache APISIX"),"."),(0,r.kt)("p",null,"AI/ML API provides a unified OpenAI-compatible API with access to ",(0,r.kt)("strong",{parentName:"p"},"300+ LLMs")," such as GPT-4, Claude, Gemini, DeepSeek, and others. This integration bridges the gap between your API infrastructure and leading AI services, enabling you to deploy intelligent features\u2014like chatbots, real-time translations, and data analysis\u2014faster than ever."),(0,r.kt)("h2",{id:"proxy-to-openai-via-aiml-api"},"Proxy to OpenAI via AI/ML API"),(0,r.kt)("h3",{id:"prerequisites"},"Prerequisites"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"https://apisix.apache.org/docs/apisix/installation-guide/"},"Install APISIX"),"."),(0,r.kt)("li",{parentName:"ol"},"Generate your API key on ",(0,r.kt)("a",{parentName:"li",href:"https://aimlapi.com/app/keys/"},"AI/ML API dashboard"),".\n",(0,r.kt)("img",{parentName:"li",src:"https://static.api7.ai/uploads/2025/07/30/dGXA7d0r_ai-ml-api-key.webp",alt:"Generate AI/ML API Key"}))),(0,r.kt)("h3",{id:"configure-the-route"},"Configure the Route"),(0,r.kt)("p",null,"Create a route and configure the ",(0,r.kt)("inlineCode",{parentName:"p"},"ai-proxy")," plugin as such:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-yaml"},'curl "http://127.0.0.1:9180/apisix/admin/routes" -X PUT \\\n  -H "X-API-KEY: ${ADMIN_API_KEY}" \\\n  -d \'{\n    "id": "ai-proxy-route",\n    "uri": "/anything",\n    "methods": ["POST"],\n    "plugins": {\n      "ai-proxy": {\n        "provider": "aimlapi",\n        "auth": {\n          "header": {\n            "Authorization": "Bearer \'"$OPENAI_API_KEY"\'" # Generated openai key from AI/ML API dashboard\n          }\n        },\n        "options":{\n          "model": "gpt-4"\n        }\n      }\n    }\n  }\'\n')),(0,r.kt)("h3",{id:"test-the-integration"},"Test the Integration"),(0,r.kt)("p",null,"Send a POST request to the route with a system prompt and a sample user question in the request body:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'curl "http://127.0.0.1:9080/anything" -X POST \\\n  -H "Content-Type: application/json" \\\n  -H "Host: api.openai.com" \\\n  -d \'{\n    "messages": [\n      { "role": "system", "content": "You are a mathematician" },\n      { "role": "user", "content": "What is 1+1?" }\n    ]\n  }\'\n')),(0,r.kt)("h3",{id:"verify-response"},"Verify Response"),(0,r.kt)("p",null,"You should receive a response similar to the following:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-json"},'{\n  ...,\n  "choices": [\n    {\n      "index": 0,\n      "finish_reason": "stop",\n      "logprobs": null,\n      "message": {\n        "role": "assistant",\n        "content": "1 + 1 equals 2.",\n        "refusal": null,\n        "annotations": []\n      }\n    }\n  ],\n  "created": 1753845968,\n  "model": "gpt-4-0613",\n  "usage": {\n    "prompt_tokens": 1449,\n    "completion_tokens": 1008,\n    "total_tokens": 2457\n  ...\n}\n')),(0,r.kt)("h2",{id:"core-use-cases"},"Core Use Cases"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Unified AI Service Management")),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Multi-Model Proxy and Load Balancing"),": Replace hardcoded vendor endpoints with a single APISIX interface, dynamically routing requests to models from OpenAI, Claude, DeepSeek, Gemini, Mistral, etc., based on cost, latency, or performance needs."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Vendor-Agnostic Workflows"),": Seamlessly switch between models (e.g., GPT-4 for creative tasks, Claude for document analysis) without code changes."))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Cost-Optimized Token Governance")),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Token-Based Budget Enforcement"),": Set per-team/monthly spending limits; auto-throttle requests when thresholds are exceeded."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Caching & Fallbacks"),": Cache frequent LLM responses (e.g., FAQ answers) or reroute to cheaper models during provider outages."))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Real-Time AI Application Scaling")),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Chatbots & Virtual Agents"),": Power low-latency conversational interfaces with streaming support for token-by-token responses."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Data Enrichment Pipelines"),": Augment APIs with AI\u2014e.g., auto-summarize user reviews or translate product descriptions on-the-fly."))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Hybrid/Multi-Cloud AI Deployment")),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Unified Control Plane"),": Manage on-prem LLMs (e.g., Llama 3) alongside cloud APIs (OpenAI, Azure) with consistent policy enforcement."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"High Availability & Fault Tolerance"),": Built-in health-checks, automatic retries and failover; if one LLM fails, traffic is rerouted within seconds to keep services alive."))),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("p",{parentName:"li"},(0,r.kt)("strong",{parentName:"p"},"Enterprise AI Security & Compliance")),(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Data Security and Compliance"),": Prompt Guard, content moderation, PII redaction and full audit logs in a single place."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"One Auth Layer for 300+ LLMs"),": Unified authentication (JWT/OAuth2/OIDC) and authorization for 300+ LLM keys and policies.")))),(0,r.kt)("h2",{id:"conclusion"},"Conclusion"),(0,r.kt)("p",null,"With AI/ML API now natively supported in Apache APISIX, you no longer have to choose between ",(0,r.kt)("strong",{parentName:"p"},"speed"),", ",(0,r.kt)("strong",{parentName:"p"},"security"),", or ",(0,r.kt)("strong",{parentName:"p"},"scale"),"\u2014you get all three."),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"One line of YAML")," turns your gateway into a 300-model AI powerhouse."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Zero code changes")," let you hot-swap GPT-4 for Claude, or route 10 % of traffic to a cheaper model for instant cost savings."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Built-in guardrails")," (PII redaction, token budgets, content moderation) keep compliance teams happy while your product team ships faster.")),(0,r.kt)("h3",{id:"more-resources"},"More Resources"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Related APISIX AI Plugins",(0,r.kt)("ul",{parentName:"li"},(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://apisix.apache.org/docs/apisix/plugins/ai-proxy/"},"ai-proxy")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://apisix.apache.org/docs/apisix/plugins/ai-proxy-multi/"},"ai-proxy-multi")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://apisix.apache.org/docs/apisix/plugins/ai-request-rewrite/"},"ai-request-rewrite")))),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"https://aimlapi.com/community"},"AI/ML API Community"))))}c.isMDXComponent=!0}}]);