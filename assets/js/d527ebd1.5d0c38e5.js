"use strict";(self.webpackChunkdoc=self.webpackChunkdoc||[]).push([[84114],{3905:(e,t,n)=>{n.d(t,{Zo:()=>d,kt:()=>c});var i=n(67294);function a(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function r(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var i=Object.getOwnPropertySymbols(e);t&&(i=i.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,i)}return n}function l(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?r(Object(n),!0).forEach((function(t){a(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):r(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function o(e,t){if(null==e)return{};var n,i,a=function(e,t){if(null==e)return{};var n,i,a={},r=Object.keys(e);for(i=0;i<r.length;i++)n=r[i],t.indexOf(n)>=0||(a[n]=e[n]);return a}(e,t);if(Object.getOwnPropertySymbols){var r=Object.getOwnPropertySymbols(e);for(i=0;i<r.length;i++)n=r[i],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(a[n]=e[n])}return a}var s=i.createContext({}),p=function(e){var t=i.useContext(s),n=t;return e&&(n="function"==typeof e?e(t):l(l({},t),e)),n},d=function(e){var t=p(e.components);return i.createElement(s.Provider,{value:t},e.children)},m={inlineCode:"code",wrapper:function(e){var t=e.children;return i.createElement(i.Fragment,{},t)}},u=i.forwardRef((function(e,t){var n=e.components,a=e.mdxType,r=e.originalType,s=e.parentName,d=o(e,["components","mdxType","originalType","parentName"]),u=p(n),c=a,g=u["".concat(s,".").concat(c)]||u[c]||m[c]||r;return n?i.createElement(g,l(l({ref:t},d),{},{components:n})):i.createElement(g,l({ref:t},d))}));function c(e,t){var n=arguments,a=t&&t.mdxType;if("string"==typeof e||a){var r=n.length,l=new Array(r);l[0]=u;var o={};for(var s in t)hasOwnProperty.call(t,s)&&(o[s]=t[s]);o.originalType=e,o.mdxType="string"==typeof e?e:a,l[1]=o;for(var p=2;p<r;p++)l[p]=n[p];return i.createElement.apply(null,l)}return i.createElement.apply(null,n)}u.displayName="MDXCreateElement"},28051:(e,t,n)=>{n.r(t),n.d(t,{contentTitle:()=>l,default:()=>d,frontMatter:()=>r,metadata:()=>o,toc:()=>s});var i=n(87462),a=(n(67294),n(3905));const r={title:"ai-rate-limiting",keywords:["Apache APISIX","API Gateway","Plugin","ai-rate-limiting"],description:"The ai-rate-limiting plugin enforces token-based rate limiting for LLM service requests, preventing overuse, optimizing API consumption, and ensuring efficient resource allocation."},l=void 0,o={unversionedId:"plugins/ai-rate-limiting",id:"version-3.12/plugins/ai-rate-limiting",isDocsHomePage:!1,title:"ai-rate-limiting",description:"The ai-rate-limiting plugin enforces token-based rate limiting for LLM service requests, preventing overuse, optimizing API consumption, and ensuring efficient resource allocation.",source:"@site/docs-apisix_versioned_docs/version-3.12/plugins/ai-rate-limiting.md",sourceDirName:"plugins",slug:"/plugins/ai-rate-limiting",permalink:"/docs/apisix/3.12/plugins/ai-rate-limiting",editUrl:"/edit#https://github.com/apache/apisix/edit/release/3.12/docs/en/latest/plugins/ai-rate-limiting.md",tags:[],version:"3.12",frontMatter:{title:"ai-rate-limiting",keywords:["Apache APISIX","API Gateway","Plugin","ai-rate-limiting"],description:"The ai-rate-limiting plugin enforces token-based rate limiting for LLM service requests, preventing overuse, optimizing API consumption, and ensuring efficient resource allocation."},sidebar:"version-3.12/docs",previous:{title:"ai-proxy-multi",permalink:"/docs/apisix/3.12/plugins/ai-proxy-multi"},next:{title:"ai-prompt-guard",permalink:"/docs/apisix/3.12/plugins/ai-prompt-guard"}},s=[{value:"Description",id:"description",children:[]},{value:"Plugin Attributes",id:"plugin-attributes",children:[]},{value:"Example",id:"example",children:[]}],p={toc:s};function d(e){let{components:t,...n}=e;return(0,a.kt)("wrapper",(0,i.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,a.kt)("h2",{id:"description"},"Description"),(0,a.kt)("p",null,"The ",(0,a.kt)("inlineCode",{parentName:"p"},"ai-rate-limiting")," plugin enforces token-based rate limiting for requests sent to LLM services. It helps manage API usage by controlling the number of tokens consumed within a specified time frame, ensuring fair resource allocation and preventing excessive load on the service. It is often used with ",(0,a.kt)("inlineCode",{parentName:"p"},"ai-proxy")," or ",(0,a.kt)("inlineCode",{parentName:"p"},"ai-proxy-multi")," plugin."),(0,a.kt)("h2",{id:"plugin-attributes"},"Plugin Attributes"),(0,a.kt)("table",null,(0,a.kt)("thead",{parentName:"table"},(0,a.kt)("tr",{parentName:"thead"},(0,a.kt)("th",{parentName:"tr",align:null},"Name"),(0,a.kt)("th",{parentName:"tr",align:null},"Type"),(0,a.kt)("th",{parentName:"tr",align:null},"Required"),(0,a.kt)("th",{parentName:"tr",align:null},"Description"))),(0,a.kt)("tbody",{parentName:"table"},(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"limit")),(0,a.kt)("td",{parentName:"tr",align:null},"integer"),(0,a.kt)("td",{parentName:"tr",align:null},"conditionally"),(0,a.kt)("td",{parentName:"tr",align:null},"The maximum number of tokens allowed to consume within a given time interval. At least one of ",(0,a.kt)("inlineCode",{parentName:"td"},"limit")," and ",(0,a.kt)("inlineCode",{parentName:"td"},"instances.limit")," should be configured.")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"time_window")),(0,a.kt)("td",{parentName:"tr",align:null},"integer"),(0,a.kt)("td",{parentName:"tr",align:null},"conditionally"),(0,a.kt)("td",{parentName:"tr",align:null},"The time interval corresponding to the rate limiting ",(0,a.kt)("inlineCode",{parentName:"td"},"limit")," in seconds. At least one of ",(0,a.kt)("inlineCode",{parentName:"td"},"time_window")," and ",(0,a.kt)("inlineCode",{parentName:"td"},"instances.time_window")," should be configured.")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"show_limit_quota_header")),(0,a.kt)("td",{parentName:"tr",align:null},"boolean"),(0,a.kt)("td",{parentName:"tr",align:null},"false"),(0,a.kt)("td",{parentName:"tr",align:null},"If true, include ",(0,a.kt)("inlineCode",{parentName:"td"},"X-AI-RateLimit-Limit-*")," to show the total quota, ",(0,a.kt)("inlineCode",{parentName:"td"},"X-AI-RateLimit-Remaining-*")," to show the remaining quota in the response header, and ",(0,a.kt)("inlineCode",{parentName:"td"},"X-AI-RateLimit-Reset-*")," to show the number of seconds left for the counter to reset, where ",(0,a.kt)("inlineCode",{parentName:"td"},"*")," is the instance name. Default: ",(0,a.kt)("inlineCode",{parentName:"td"},"true"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"limit_strategy")),(0,a.kt)("td",{parentName:"tr",align:null},"string"),(0,a.kt)("td",{parentName:"tr",align:null},"false"),(0,a.kt)("td",{parentName:"tr",align:null},"Type of token to apply rate limiting. ",(0,a.kt)("inlineCode",{parentName:"td"},"total_tokens"),", ",(0,a.kt)("inlineCode",{parentName:"td"},"prompt_tokens"),", and ",(0,a.kt)("inlineCode",{parentName:"td"},"completion_tokens")," values are returned in each model response, where ",(0,a.kt)("inlineCode",{parentName:"td"},"total_tokens")," is the sum of ",(0,a.kt)("inlineCode",{parentName:"td"},"prompt_tokens")," and ",(0,a.kt)("inlineCode",{parentName:"td"},"completion_tokens"),". Default: ",(0,a.kt)("inlineCode",{parentName:"td"},"total_tokens"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"instances")),(0,a.kt)("td",{parentName:"tr",align:null},"array","[object]"),(0,a.kt)("td",{parentName:"tr",align:null},"conditionally"),(0,a.kt)("td",{parentName:"tr",align:null},"LLM instance rate limiting configurations.")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"instances.name")),(0,a.kt)("td",{parentName:"tr",align:null},"string"),(0,a.kt)("td",{parentName:"tr",align:null},"true"),(0,a.kt)("td",{parentName:"tr",align:null},"Name of the LLM service instance.")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"instances.limit")),(0,a.kt)("td",{parentName:"tr",align:null},"integer"),(0,a.kt)("td",{parentName:"tr",align:null},"true"),(0,a.kt)("td",{parentName:"tr",align:null},"The maximum number of tokens allowed to consume within a given time interval.")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"instances.time_window")),(0,a.kt)("td",{parentName:"tr",align:null},"integer"),(0,a.kt)("td",{parentName:"tr",align:null},"true"),(0,a.kt)("td",{parentName:"tr",align:null},"The time interval corresponding to the rate limiting ",(0,a.kt)("inlineCode",{parentName:"td"},"limit")," in seconds.")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"rejected_code")),(0,a.kt)("td",{parentName:"tr",align:null},"integer"),(0,a.kt)("td",{parentName:"tr",align:null},"false"),(0,a.kt)("td",{parentName:"tr",align:null},"The HTTP status code returned when a request exceeding the quota is rejected. Default: ",(0,a.kt)("inlineCode",{parentName:"td"},"503"))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},(0,a.kt)("inlineCode",{parentName:"td"},"rejected_msg")),(0,a.kt)("td",{parentName:"tr",align:null},"string"),(0,a.kt)("td",{parentName:"tr",align:null},"false"),(0,a.kt)("td",{parentName:"tr",align:null},"The response body returned when a request exceeding the quota is rejected.")))),(0,a.kt)("p",null,"If ",(0,a.kt)("inlineCode",{parentName:"p"},"limit")," is configured, ",(0,a.kt)("inlineCode",{parentName:"p"},"time_window")," also needs to be configured. Else, just specifying ",(0,a.kt)("inlineCode",{parentName:"p"},"instances")," will also suffice."),(0,a.kt)("h2",{id:"example"},"Example"),(0,a.kt)("p",null,"Create a route as such and update with your LLM providers, models, API keys, and endpoints:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},'curl "http://127.0.0.1:9180/apisix/admin/routes" -X PUT \\\n  -H "X-API-KEY: ${ADMIN_API_KEY}" \\\n  -d \'{\n    "id": "ai-rate-limiting-route",\n    "uri": "/anything",\n    "methods": ["POST"],\n    "plugins": {\n      "ai-proxy": {\n        "provider": "openai",\n        "auth": {\n          "header": {\n            "Authorization": "Bearer \'"$API_KEY"\'"\n          }\n        },\n        "options": {\n          "model": "gpt-35-turbo-instruct",\n          "max_tokens": 512,\n          "temperature": 1.0\n        }\n      },\n      "ai-rate-limiting": {\n        "limit": 300,\n        "time_window": 30,\n        "limit_strategy": "prompt_tokens"\n      }\n    }\n  }\'\n')),(0,a.kt)("p",null,"Send a POST request to the route with a system prompt and a sample user question in the request body:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-shell"},'curl "http://127.0.0.1:9080/anything" -X POST \\\n  -H "Content-Type: application/json" \\\n  -d \'{\n    "messages": [\n      { "role": "system", "content": "You are a mathematician" },\n      { "role": "user", "content": "What is 1+1?" }\n    ]\n  }\'\n')),(0,a.kt)("p",null,"You should receive a response similar to the following:"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-json"},'{\n  ...\n  "model": "deepseek-chat",\n  "choices": [\n    {\n      "index": 0,\n      "message": {\n        "role": "assistant",\n        "content": "1 + 1 equals 2. This is a fundamental arithmetic operation where adding one unit to another results in a total of two units."\n      },\n      "logprobs": null,\n      "finish_reason": "stop"\n    }\n  ],\n  ...\n}\n')),(0,a.kt)("p",null,"If rate limiting quota of 300 tokens has been consumed in a 30-second window, the additional requests will all be rejected."))}d.isMDXComponent=!0}}]);